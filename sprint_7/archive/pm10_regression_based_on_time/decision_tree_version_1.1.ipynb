{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9227138e-64fb-4fa5-bc78-8985aec5af5c",
   "metadata": {},
   "source": [
    "## Decision Tree V1\n",
    "- all datetime feature\n",
    "- random cross validation\n",
    "\n",
    "**Hyperparameter for tweeking:**\n",
    "- maximale Baumtiefe\n",
    "- Mindestanzahl an Daten pro Blatt\n",
    "- Mindestanzahl an Daten pro Knoten\n",
    "- Features\n",
    "\n",
    "**Regularisierung:**\n",
    "- Pruning\n",
    "\n",
    "**Metriken:**\n",
    "- mean_absolute_error\n",
    "- mean_squared_error\n",
    "- median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88f4eb-b56f-4033-9f08-43cfc488ae99",
   "metadata": {},
   "source": [
    "#### **_PREPARATION_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec8f4db-5c81-4b88-8c1c-f8dccff35c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL THE JSONS INTO ONE DATAFRAME\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032f2b23-46ac-4db7-850e-ff7739a4eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (542555, 6)\n"
     ]
    }
   ],
   "source": [
    "# Set the search path for files (assuming the directory is relative to the current script)\n",
    "file_path_mc124 = os.path.join(\"..\", \"mc124_data\", \"*.json\")\n",
    "files = glob.glob(file_path_mc124)\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "li_all_files = []\n",
    "\n",
    "# Loop through list of files and read each one into a dataframe and append to list\n",
    "for f in files:\n",
    "    # Read in json\n",
    "    temp_df = pd.read_json(f)\n",
    "    # Append df to list\n",
    "    li_all_files.append(temp_df)\n",
    "\n",
    "# Optionally concatenate all dataframes into one if needed\n",
    "if li_all_files:\n",
    "    combined_df = pd.concat(li_all_files)\n",
    "    print(f'Combined dataframe shape: {combined_df.shape}')\n",
    "else:\n",
    "    print('No dataframes were created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899dced3-3997-4824-ae92-c3d496342a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>core</th>\n",
       "      <th>component</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-28 23:00:00+01:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>no</td>\n",
       "      <td>no_1h</td>\n",
       "      <td>1h</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime station core component period  value\n",
       "3  2021-02-28 23:00:00+01:00   mc124   no     no_1h     1h   28.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3907114f-34e2-4755-ac85-9d74020c16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 542555 entries, 0 to 3654\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   datetime  542555 non-null  datetime64[ns]\n",
      " 1   station   542555 non-null  object        \n",
      " 2   core      542555 non-null  object        \n",
      " 3   value     539422 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 20.7+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a_n_n\\AppData\\Local\\Temp\\ipykernel_4764\\2472174257.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced['datetime'] = pd.to_datetime(df_reduced['datetime'], format='mixed')\n"
     ]
    }
   ],
   "source": [
    "# FILTER BY PARTICLE AND ONLY KEEP THE DATETIME, STATION, PERIOD AND VALUE FEATURE SINCE THE REST ARE CONSTANT INFORMATION (station, core, component, period)\n",
    "df_reduced = combined_df[['datetime', 'station', 'core', 'value']]\n",
    "df_reduced.sample(3)\n",
    "\n",
    "# CUT OFF THE TIMEZONE INFORMATION FROM THE DATETIME TO AVOID CONVERSION ISSUES DUE TO TIME CHANGE IN MARCH AND OCTOBER\n",
    "df_reduced.loc[:, 'datetime'] = df_reduced['datetime'].astype(str).str.slice(0, 19)\n",
    "#df_pm10_reduced.loc[:, 'datetime'] = pd.to_datetime(df_pm10_reduced['datetime'], format='mixed')\n",
    "df_reduced['datetime'] = pd.to_datetime(df_reduced['datetime'], format='mixed')\n",
    "df_reduced.loc[:, 'datetime'] = df_reduced['datetime'].dt.tz_localize(None)\n",
    "df_reduced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578822bd-0311-4067-a83f-11868d7436b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>core</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2011-12-07 03:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>nox</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2009-05-14 21:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>no</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2022-10-24 03:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>pm10</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime station  core  value\n",
       "1790 2011-12-07 03:00:00   mc124   nox   37.0\n",
       "1231 2009-05-14 21:00:00   mc124    no    6.0\n",
       "940  2022-10-24 03:00:00   mc124  pm10   16.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ecf72c9-0c5b-41a1-a706-70a5ef24ad98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a_n_n\\AppData\\Local\\Temp\\ipykernel_4764\\493841492.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced['hour'] = df_reduced['datetime'].dt.strftime('%H')  # Hour (00-23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>core</th>\n",
       "      <th>value</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2024-04-12 13:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>no2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>04</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>2022-11-19 09:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>no</td>\n",
       "      <td>90.0</td>\n",
       "      <td>09</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2024-05-24 02:00:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "      <td>05</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime station core  value hour day month  year\n",
       "2212 2024-04-12 13:00:00   mc124  no2   35.0   13  12    04  2024\n",
       "1393 2022-11-19 09:00:00   mc124   no   90.0   09  19    11  2022\n",
       "883  2024-05-24 02:00:00   mc124   no    2.0   02  24    05  2024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use loc to add it to every for every row\n",
    "df_reduced['hour'] = df_reduced['datetime'].dt.strftime('%H')  # Hour (00-23)\n",
    "df_reduced['day'] = df_reduced['datetime'].dt.strftime('%d')  # Day of the month (01-31)\n",
    "df_reduced['month'] = df_reduced['datetime'].dt.strftime('%m')  # Month (01-12)\n",
    "df_reduced['year'] = df_reduced['datetime'].dt.strftime('%Y')  # Month (01-12)\n",
    "df_reduced.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cc1304-8b05-467c-b0e8-a0bedbaeb1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 542555 entries, 0 to 3654\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   datetime     542555 non-null  datetime64[ns]\n",
      " 1   station      542555 non-null  object        \n",
      " 2   core         542555 non-null  object        \n",
      " 3   pm10_value   539422 non-null  float64       \n",
      " 4   hour         542555 non-null  object        \n",
      " 5   day          542555 non-null  int32         \n",
      " 6   month        542555 non-null  int32         \n",
      " 7   year         542555 non-null  int32         \n",
      " 8   day_of_week  542555 non-null  int64         \n",
      " 9   is_weekend   542555 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int32(3), int64(2), object(3)\n",
      "memory usage: 39.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# add day of the week to dataframe\n",
    "import calendar\n",
    "\n",
    "days = {\n",
    "    0: \"Monday\",\n",
    "    1: \"Tuesday\",\n",
    "    2: \"Wednesday\",\n",
    "    3: \"Thursday\",\n",
    "    4: \"Friday\",\n",
    "    5: \"Saturday\",\n",
    "    6: \"Sunday\",\n",
    "}\n",
    "\n",
    "df_daytime = df_reduced\n",
    "# convert the 'day', 'month', and 'year' columns to integers\n",
    "df_daytime['day'] = df_reduced['day'].astype(int)\n",
    "df_daytime['month'] = df_reduced['month'].astype(int)\n",
    "df_daytime['year'] = df_reduced['year'].astype(int)\n",
    "\n",
    "# function to determine the day of the week\n",
    "def get_day_of_week(row):\n",
    "    return calendar.weekday(row['year'], row['month'], row['day'])\n",
    "\n",
    "# function to determine if day is weekday or weekend \n",
    "def is_weekend(day_number):\n",
    "    return 1 if day_number >= 5 else 0\n",
    "    #day_number >= 5 ? 1 : 0\n",
    "    \n",
    "# apply the functions to create the new columns\n",
    "df_daytime['day_of_week'] = df_daytime.apply(get_day_of_week, axis=1)\n",
    "df_daytime['is_weekend'] = df_daytime['day_of_week'].apply(is_weekend)\n",
    "\n",
    "df_daytime.rename(columns={'value': 'pm10_value'}, inplace=True)\n",
    "\n",
    "df_daytime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d29701-a0d1-445f-8da9-e0a8324d7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 539422 entries, 0 to 3654\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   datetime     539422 non-null  datetime64[ns]\n",
      " 1   station      539422 non-null  object        \n",
      " 2   core         539422 non-null  object        \n",
      " 3   pm10_value   539422 non-null  float64       \n",
      " 4   hour         539422 non-null  object        \n",
      " 5   day          539422 non-null  int32         \n",
      " 6   month        539422 non-null  int32         \n",
      " 7   year         539422 non-null  int32         \n",
      " 8   day_of_week  539422 non-null  int64         \n",
      " 9   is_weekend   539422 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int32(3), int64(2), object(3)\n",
      "memory usage: 39.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_daytime.dropna(inplace=True)\n",
    "df_daytime.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf48370-f694-414b-98fe-41e2c0d01169",
   "metadata": {},
   "source": [
    "#### **_ACTUAL MODEL TRAINING_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d582f3-651d-423a-b174-2126abc9e9a1",
   "metadata": {},
   "source": [
    "#### Part 1: create decision tree on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ada179-3fc4-4383-bcc9-aee1c9abaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and to be predicted value\n",
    "y = df_daytime['pm10_value']\n",
    "X = df_daytime[['hour', 'year', 'day_of_week', 'is_weekend']]\n",
    "\n",
    "# SCALING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39a4cb64-ec4b-435e-aea5-b47a0431e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af6cf8df-7197-4513-8966-8e2968269bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1457118119110632"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7d760ce-5a96-49b1-8351-d9792ba05c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14182334982175882"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "451ed659-631f-4162-8112-8d786ab74f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24453117558268656"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=2000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b2019f8-05d0-41ca-899f-40bd7d9a01d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11437126086933513"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c06c540-8a24-4f95-a070-752db0757984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "fit_time: 0.51 (+/- 0.12)\n",
      "score_time: 0.05 (+/- 0.01)\n",
      "test_mean_absolute_error: -34.19 (+/- 9.38)\n",
      "train_mean_absolute_error: -32.99 (+/- 2.68)\n",
      "test_mean_squared_error: -2964.36 (+/- 1580.67)\n",
      "train_mean_squared_error: -2821.03 (+/- 378.08)\n",
      "test_median_absolute_error: -22.86 (+/- 5.00)\n",
      "train_median_absolute_error: -20.71 (+/- 1.94)\n"
     ]
    }
   ],
   "source": [
    "# cross validate\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "\n",
    "# scores = cross_validate(knn, data_scaled, iris.target, return_train_score=True, cv=5)\n",
    "# scores\n",
    "# train_scores = scores[\"train_score\"]\n",
    "# test_scores = scores[\"test_score\"]\n",
    "# train_scores.mean()\n",
    "# test_scores.mean()\n",
    "# test_scores.std()\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# Create a DecisionTreeRegressor\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "# Define your scoring functions\n",
    "scorers = {\n",
    "    'mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'median_absolute_error': make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_validate(decision_tree, X, y, cv=5, scoring=scorers, return_train_score=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validation scores:\")\n",
    "for scorer, score in scores.items():\n",
    "    print(f\"{scorer}: {np.mean(score):.2f} (+/- {np.std(score):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a01fde82-2d7a-4d2f-bcbd-ffebc3a12913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.41242266, 0.48479939, 0.5263772 , 0.63439274, 0.61335135]),\n",
       " 'score_time': array([0.04782224, 0.05198812, 0.05761933, 0.07002497, 0.06286621]),\n",
       " 'test_mean_absolute_error': array([-45.68906005, -43.23609553, -34.32319257, -26.38275244,\n",
       "        -21.33665478]),\n",
       " 'test_mean_squared_error': array([-4647.09647197, -4862.78049234, -2789.90800272, -1595.44813097,\n",
       "         -926.55201736]),\n",
       " 'test_median_absolute_error': array([-30.82962963, -25.11111111, -23.09137056, -18.53066667,\n",
       "        -16.71428571])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f5045-7dd2-4fd3-8e58-5b11c3bcdcec",
   "metadata": {},
   "source": [
    "## TODO: REMOVE CONSISTENTLY HEAVY OUTLIER\n",
    "- EASTER\n",
    "- CHRISTMAS\n",
    "-> take one year and analyze month for month (daily data)\n",
    "-> additional column: crazy_holiday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3810e6b2-1065-4092-9be7-390419ab1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PM10 value: 51.14\n"
     ]
    }
   ],
   "source": [
    "# average pm10 value for comparison to the error rates\n",
    "average_pm10 = df_daytime['pm10_value'].mean()\n",
    "print(f\"Average PM10 value: {average_pm10:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077629f5-bb4f-434b-9cf8-7ae5a36c5b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
