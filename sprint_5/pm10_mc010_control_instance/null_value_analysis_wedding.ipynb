{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8280dbf8-e0d0-44ba-86a7-190605680f6c",
   "metadata": {},
   "source": [
    "Goals:\n",
    "- compare average pm10 of each year --> x-axe == year\n",
    "- compare average pm10 of each month --> x-axe == month && hue == year\n",
    "\n",
    "Todo:\n",
    "- create dataframe which contains the total pm10, total days and averages of each year\n",
    "    - columns: year, total pm10, total days, average pm10\n",
    "    - rows: 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2020, 2023, (2024 as outlier with 5 months done)\n",
    " \n",
    "- create dataframe which contains (total pm10, total days and) average of each month per year\n",
    "    - columns: month, avg 2013, avg 2014, avg 2014, etc\n",
    "    - rows: jan, feb, march, april, may, june, july, august, september, october, november, december"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f522c-e4a0-41e5-b4fe-9a48de5d8093",
   "metadata": {},
   "source": [
    "#### Yearly Data Summary Idea - Table view\n",
    "\n",
    "| Year | Total PM10 | Total Days | Average PM10 |\n",
    "|------|------------|------------|--------------|\n",
    "| 2013 |            |            |              |\n",
    "| 2014 |            |            |              |\n",
    "| 2015 |            |            |              |\n",
    "| 2016 |            |            |              |\n",
    "| 2017 |            |            |              |\n",
    "| 2018 |            |            |              |\n",
    "| 2019 |            |            |              |\n",
    "| 2020 |            |            |              |\n",
    "| 2021 |            |            |              |\n",
    "| 2022 |            |            |              |\n",
    "| 2023 |            |            |              |\n",
    "| 2024 |            |            |              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e55d33-cac6-4f0f-89d8-6ed27e86210b",
   "metadata": {},
   "source": [
    "#### Monthly Data Summary Idea - Table view\n",
    "\n",
    "| Month     | Avg 2013 | Avg 2014 | Avg 2015 | Avg 2016 | Avg 2017 | Avg 2018 | Avg 2019 | Avg 2020 | Avg 2021 | Avg 2022 | Avg 2023 | Avg 2024 |\n",
    "|-----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
    "| January   |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| February  |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| March     |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| April     |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| May       |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| June      |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| July      |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| August    |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| September |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| October   |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| November  |          |          |          |          |          |          |          |          |          |          |          |          |\n",
    "| December  |          |          |          |          |          |          |          |          |          |          |          |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0a5e6-6317-4608-8e0c-138c58b5b169",
   "metadata": {},
   "source": [
    "This way no standard deviation tho?? Need to look into the documentation again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472d3815-afaf-4cab-98f3-52dbc87e2afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (627044, 6)\n"
     ]
    }
   ],
   "source": [
    "# GET ALL THE JSONS INTO ONE DATAFRAME\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Set the search path for files (assuming the directory is relative to the current script)\n",
    "file_path_mc124 = os.path.join(\"..\", \"mc010_wedding\", \"*.json\")\n",
    "files = glob.glob(file_path_mc124)\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "li_all_files = []\n",
    "\n",
    "# Loop through list of files and read each one into a dataframe and append to list\n",
    "for f in files:\n",
    "    # Read in json\n",
    "    temp_df = pd.read_json(f)\n",
    "    # Append df to list\n",
    "    li_all_files.append(temp_df)\n",
    "\n",
    "# Optionally concatenate all dataframes into one if needed\n",
    "if li_all_files:\n",
    "    combined_df = pd.concat(li_all_files)\n",
    "    print(f'Combined dataframe shape: {combined_df.shape}')\n",
    "else:\n",
    "    print('No dataframes were created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2ff041-6beb-442d-a118-3ebbe318b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>core</th>\n",
       "      <th>component</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>2016-10-12T14:00:00+02:00</td>\n",
       "      <td>mc010</td>\n",
       "      <td>cht</td>\n",
       "      <td>cht_1h</td>\n",
       "      <td>1h</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime station core component period  value\n",
       "3261  2016-10-12T14:00:00+02:00   mc010  cht    cht_1h     1h    1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK SAMPLE OF DATAFRAME\n",
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae655b73-5f4d-48e7-96d8-6fcd07fd1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-31 23:00:00+01:00</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-01-31 22:00:00+01:00</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-01-31 21:00:00+01:00</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-01-31 20:00:00+01:00</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-01-31 19:00:00+01:00</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime  value\n",
       "0   2014-01-31 23:00:00+01:00   75.0\n",
       "7   2014-01-31 22:00:00+01:00   74.0\n",
       "14  2014-01-31 21:00:00+01:00   72.0\n",
       "21  2014-01-31 20:00:00+01:00   73.0\n",
       "28  2014-01-31 19:00:00+01:00   67.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILTER BY pm10 AND ONLY KEEP THE DATETIME AND VALUE FEATURE SINCE THE REST IS FIX\n",
    "df_pm10 = combined_df[(combined_df['core'] == 'pm10')]\n",
    "df_pm10_reduced = df_pm10[['datetime', 'value']]\n",
    "df_pm10_reduced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d644b8-2855-467e-bed3-ac4ab4990d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_values_complete = df_pm10_reduced['value'].isna().sum()\n",
    "nan_values_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709c835b-a338-4643-8206-05eebeb24e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>2014-01-06 10:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2014-01-06 09:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>2014-01-06 08:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>2014-01-06 07:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>2014-01-06 06:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>2014-01-02 11:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>2014-01-02 10:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>2014-01-02 09:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>2014-01-02 08:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>2014-01-02 07:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime  value\n",
       "4291  2014-01-06 10:00:00+01:00    NaN\n",
       "4298  2014-01-06 09:00:00+01:00    NaN\n",
       "4305  2014-01-06 08:00:00+01:00    NaN\n",
       "4312  2014-01-06 07:00:00+01:00    NaN\n",
       "4319  2014-01-06 06:00:00+01:00    NaN\n",
       "...                         ...    ...\n",
       "4956  2014-01-02 11:00:00+01:00    NaN\n",
       "4963  2014-01-02 10:00:00+01:00    NaN\n",
       "4970  2014-01-02 09:00:00+01:00    NaN\n",
       "4977  2014-01-02 08:00:00+01:00    NaN\n",
       "4984  2014-01-02 07:00:00+01:00    NaN\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows = df_pm10_reduced[df_pm10_reduced['value'].isna()]\n",
    "nan_rows.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee2486d-7c90-47d7-8b85-11a9a2c9ab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station</th>\n",
       "      <th>core</th>\n",
       "      <th>component</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-31T23:00:00+01:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>pm10</td>\n",
       "      <td>pm10_1h</td>\n",
       "      <td>1h</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-31T22:00:00+01:00</td>\n",
       "      <td>mc124</td>\n",
       "      <td>pm10</td>\n",
       "      <td>pm10_1h</td>\n",
       "      <td>1h</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime station  core component period  value\n",
       "0  2023-10-31T23:00:00+01:00   mc124  pm10   pm10_1h     1h    6.0\n",
       "5  2023-10-31T22:00:00+01:00   mc124  pm10   pm10_1h     1h    6.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if also NaN when loading file singualily or if globbing it caused the null value\n",
    "file_path_oct23 = os.path.join(\"mc124_data\",\"mc124_data_2023_10.json\") \n",
    "df = pd.read_json(file_path_oct23)\n",
    "df_pm10_oct23 = df[(df['core'] == 'pm10')]\n",
    "df_pm10_oct23.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e99c34-9006-470d-beac-8282c45f0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_values_oct23 = df_pm10_oct23['value'].isna().sum()\n",
    "nan_values_oct23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628c990d-b0aa-450a-badf-174897a6f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if also NaN when loading file singualily or if globbing it caused the null value\n",
    "file_path_mar16 = os.path.join(\"mc124_data\",\"mc124_data_2016_03.json\") \n",
    "df = pd.read_json(file_path_mar16)\n",
    "df_pm10_mar16 = df[(df['core'] == 'pm10')]\n",
    "nan_values_mar16 = df_pm10_mar16['value'].isna().sum()\n",
    "nan_values_mar16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1747e5f-73c4-41fb-8299-2c2c9a08083e",
   "metadata": {},
   "source": [
    "#### NaN is not caused by me but inherently in there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526068a-4977-4e9f-b148-d45f0f53121d",
   "metadata": {},
   "source": [
    "### DATETIME nicht nur anderer Datentyp, sondern auch Teilweise falsche regex -- AHHHHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511d3f6c-9455-4ef9-b53b-7542e005939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91242 entries, 0 to 4242\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   datetime  91242 non-null  object \n",
      " 1   value     90669 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# QUICKFIX: convert datetime to UTC\n",
    "\n",
    "#df_pm10_reduced.loc[:, 'datetime'] = pd.to_datetime(df_pm10_reduced['datetime'], utc=True)\n",
    "#df_pm10_reduced['datetime'] = pd.to_datetime(df_pm10_reduced['datetime'], utc=True)\n",
    "#df_pm10_reduced['datetime'].dt.tz_convert('UTC') \n",
    "#df_pm10_reduced['datetime'] = pd.to_datetime(df_pm10_reduced['datetime'], utc=True)\n",
    "#df_pm10_reduced['datetime'] = df_pm10_reduced['datetime'].astype(str)\n",
    "# Convert 'datetime' column back to datetime format\n",
    "#df_pm10_reduced['datetime'] = pd.to_datetime(df_pm10_reduced['datetime'], utc=True)\n",
    "df_pm10_reduced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1fab09d-8f51-472f-aae5-d188af43d673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>2023-12-11 00:00:00+01:00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2017-03-21T21:00:00+01:00</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>2018-03-07T16:00:00+01:00</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>2022-07-20 04:00:00+02:00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>2023-12-04 03:00:00+01:00</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>2014-08-17 04:00:00+02:00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>2021-10-13T16:00:00+02:00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>2022-01-19 18:00:00+01:00</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>2023-08-09 04:00:00+02:00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>2018-02-15 05:00:00+01:00</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime  value\n",
       "3018  2023-12-11 00:00:00+01:00   12.0\n",
       "1446  2017-03-21T21:00:00+01:00   13.0\n",
       "3492  2018-03-07T16:00:00+01:00   41.0\n",
       "1698  2022-07-20 04:00:00+02:00   15.0\n",
       "4008  2023-12-04 03:00:00+01:00   24.0\n",
       "2485  2014-08-17 04:00:00+02:00   12.0\n",
       "2634  2021-10-13T16:00:00+02:00    8.0\n",
       "1758  2022-01-19 18:00:00+01:00   17.0\n",
       "3282  2023-08-09 04:00:00+02:00    6.0\n",
       "1980  2018-02-15 05:00:00+01:00   36.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm10_reduced.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442371de-9175-43e8-896a-2967379a8c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_values = df_pm10_reduced['value'].isna().sum()\n",
    "nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a167adf7-8165-48b1-9473-63c019b57503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SORT BY datetime AS INDEX\n",
    "df_pm10_reduced_index = df_pm10_reduced.set_index('datetime')\n",
    "nan_values_new_index = df_pm10_reduced['value'].isna().sum()\n",
    "nan_values_new_index\n",
    "#df_pm10_reduced_sorted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c673f27b-f71c-4b92-a6dd-f307a19c6be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm10_reduced_sorted = df_pm10_reduced.sort_index()\n",
    "nan_values_sorted = df_pm10_reduced_sorted['value'].isna().sum()\n",
    "nan_values_sorted\n",
    "#df_pm10_reduced_sorted.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b3609a-8da5-42fa-b358-d9b82e73ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove march of 2016 since it contains the majority of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc177212-22e4-4084-ae0a-ba9929b491fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with extracted year and month:\n",
      "                       datetime  year  month\n",
      "0     2014-01-31 23:00:00+01:00  2014      1\n",
      "7     2014-01-31 22:00:00+01:00  2014      1\n",
      "14    2014-01-31 21:00:00+01:00  2014      1\n",
      "21    2014-01-31 20:00:00+01:00  2014      1\n",
      "28    2014-01-31 19:00:00+01:00  2014      1\n",
      "...                         ...   ...    ...\n",
      "4218  2024-05-01 04:00:00+02:00  2024      5\n",
      "4224  2024-05-01 03:00:00+02:00  2024      5\n",
      "4230  2024-05-01 02:00:00+02:00  2024      5\n",
      "4236  2024-05-01 01:00:00+02:00  2024      5\n",
      "4242  2024-05-01 00:00:00+02:00  2024      5\n",
      "\n",
      "[91242 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a_n_n\\AppData\\Local\\Temp\\ipykernel_16076\\855985485.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pm10_reduced[['year', 'month']] = df_pm10_reduced['datetime'].apply(extract_year_month).apply(pd.Series)\n",
      "C:\\Users\\a_n_n\\AppData\\Local\\Temp\\ipykernel_16076\\855985485.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pm10_reduced[['year', 'month']] = df_pm10_reduced['datetime'].apply(extract_year_month).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_year_month(datetime_obj):\n",
    "    # Convert to string if it's not already\n",
    "    if isinstance(datetime_obj, pd.Timestamp):\n",
    "        datetime_str = datetime_obj.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "    elif isinstance(datetime_obj, str):\n",
    "        datetime_str = datetime_obj\n",
    "    else:\n",
    "        return (np.nan, np.nan)  # Return NaN if datetime_obj is not string or Timestamp\n",
    "\n",
    "    # Regex pattern to match date components (YYYY-MM)\n",
    "    pattern = r'(\\d{4})-(\\d{2})'\n",
    "\n",
    "    # Use regex to find year and month\n",
    "    match = re.search(pattern, datetime_str)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        month = int(match.group(2))\n",
    "        return (year, month)\n",
    "    else:\n",
    "        return (np.nan, np.nan)  # Return NaN if pattern not found\n",
    "\n",
    "# Apply function to extract year and month\n",
    "#df_pm10_reduced['year'], df_pm10_reduced['month'] = zip(*df_pm10_reduced['datetime'].apply(extract_year_month))\n",
    "df_pm10_reduced[['year', 'month']] = df_pm10_reduced['datetime'].apply(extract_year_month).apply(pd.Series)\n",
    "print(\"DataFrame with extracted year and month:\")\n",
    "print(df_pm10_reduced[['datetime', 'year', 'month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e53a621-16c1-4ebb-9091-d8bd8ecb03a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count by month:\n",
      "    year  month  NaN_count\n",
      "0   2014      1        131\n",
      "1   2014      3         55\n",
      "2   2014      4         13\n",
      "3   2014      5          3\n",
      "4   2014      7         32\n",
      "5   2014      8          2\n",
      "6   2014     10          2\n",
      "7   2015      1          1\n",
      "8   2015      5          3\n",
      "9   2015      6          1\n",
      "10  2015      7          1\n",
      "11  2015      9          1\n",
      "12  2015     10          1\n",
      "13  2015     11          2\n",
      "14  2016      3          1\n",
      "15  2016      6         31\n",
      "16  2016      8         32\n",
      "17  2016      9          1\n",
      "18  2016     10          1\n",
      "19  2016     11         40\n",
      "20  2017      2          2\n",
      "21  2017      3          6\n",
      "22  2017      4          1\n",
      "23  2017      5          1\n",
      "24  2017      6         11\n",
      "25  2017      9         34\n",
      "26  2017     10         12\n",
      "27  2017     11         26\n",
      "28  2017     12          1\n",
      "29  2018      2          2\n",
      "30  2018      3          1\n",
      "31  2018      4          1\n",
      "32  2018      6          3\n",
      "33  2018     10          3\n",
      "34  2018     11         28\n",
      "35  2019      3          1\n",
      "36  2019      5          3\n",
      "37  2019      6          1\n",
      "38  2019     10          4\n",
      "39  2019     11         25\n",
      "40  2020      6          1\n",
      "41  2020      9          1\n",
      "42  2020     10          1\n",
      "43  2020     12          1\n",
      "44  2021      8          2\n",
      "45  2021     10          2\n",
      "46  2021     11          2\n",
      "47  2022      2         13\n",
      "48  2022      4          2\n",
      "49  2022      5          2\n",
      "50  2022      6          3\n",
      "51  2022      9          1\n",
      "52  2022     10          1\n",
      "53  2023      6          3\n",
      "54  2023      7          3\n",
      "55  2023      9          3\n",
      "56  2023     10          3\n",
      "57  2023     11          1\n",
      "58  2024      3          1\n",
      "59  2024      4          1\n",
      "60  2024      5          6\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where value is NaN\n",
    "nan_rows = df_pm10_reduced[df_pm10_reduced['value'].isna()]\n",
    "\n",
    "# Count NaN values by month\n",
    "nan_count_by_month = nan_rows.groupby(['year', 'month']).size().reset_index(name='NaN_count')\n",
    "\n",
    "# Display the NaN count by month\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"NaN count by month:\")\n",
    "print(nan_count_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911e004-8cde-4ad5-b75c-469569a06683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
